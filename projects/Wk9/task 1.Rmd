---
title: "R Notebook"
output: html_notebook
---
PDA Data Transformation Task
For this task you will be working with some (synthetic) second-hand toy sales data, specifically cleaning and joining the data, as well as considering table relationships and data storage.

Please work through your answers in an .Rmd, and then knit to html/pdf for your submission.
```{r}
library(tidyverse)
```

1
Load in the transaction data and create a column date from the day, month and year columns.
```{r}
transaction <- read_csv("raw_data/toy_transactions.csv") %>% 
  janitor::clean_names() %>% unite(date, c("year", "month", "day"), sep = "-")
```


2
Load in the toys data and:

Convert the weight column to numeric.
Split the extra information from the product into a new column, so you have two columns: product_name and product_title. Make sure you don’t have any extra whitespace in either column.
```{r}
toy <- read_csv("raw_data/toys.csv", col_types = cols(`weight` = col_number())) %>% janitor::clean_names() %>% 
  separate(product, c("product_name", "product_title"), sep = " - ")
```







3
Load in the dataset on quality labels and:
description 
Remove the unnecessary information for each descriptor
Replace the categories so ‘Awesome’ and ‘Very Awesome’ become ‘Good’ and ‘Very Good’. Do the same thing for ‘Awful’ replacing it with ‘Bad’.
```{r}
quality <- read_csv("raw_data/quality.csv") %>% 
  janitor::clean_names() %>% 
  mutate(description = str_sub(description, start = 10)) %>% 
  mutate(description = str_replace(description,"Awesome", "Good")) %>% 
  mutate(description = str_replace(description,"Awful", "Bad"))
```


4
With fs::dir_ls() you can first list all files which meet a certain regex pattern (regexp argument). So for example, any files that have a .csv extension. You can then pipe those file path names into purrr::map_dfr() to apply read_csv() to all of them and bind them all into one dataframe.

Here is a tutorial on how to do it

Using the steps above, create a dataframe called customers which contains data on customers from all countries by reading in and binding all customer datasets in one pipeline.

```{r}
library(fs)
data_dir <- "raw_data"
fs::dir_ls(data_dir)
customers <- fs::dir_ls(data_dir, regexp = "customers.csv$")%>% 
  map_dfr(read_csv)
```



5
Impute missing values in numeric columns with the median value of customers with the same gender and country. For example, a customer whose gender is female and whose country is Australia with a missing age should get the median age of all Australian females in the dataset.

Hint: You can combine a group by() with mutate(across()) to apply coalesce across columns which meet a logical criteria specified with where(). Also remember, in across() we can define our own anonymous function like so ~ mean(.x, na.rm = TRUE) where the .x represents what is being iterated on (when using across, this is the columns).

```{r}
customers <-customers %>% 
  group_by(customer_country, customer_gender) %>% 
  mutate(across(where(is.numeric), ~ coalesce(.x, mean(.x, na.rm = TRUE))))
```



6
Create a star schema and save the image for uploading. The star schema should show the relationships between your four current datasets (transactions, toy details, customers, and quality). You can make it using https://excalidraw.com or https://app.diagrams.net or any other tool that you find useful. Below is an example star schema:

```{r}
names(toy)

names(transaction)

names(customers)

names(quality)
```


7
Join your four cleaned datasets together and call the joined dataset toys_joined. This join should keep all observations from all tables.
```{r}
toys_joined <- toy %>% 
  full_join(quality, by = c("quality" = "id")) %>% 
  full_join(transaction, by = c("id" = "toy_id")) %>% 
  full_join(customers, by = c("customer_id" = "id"))
```


8
Are there any ethical and legal considerations with storing this data in its current state?

Write a short answer

This data has a lot of personal information such as customer's weight, height,
and names. All together, there are a lot of information we can work out 
from it. We can guess their ethical origin from names and can work out 
some health information from weight and height. 

9
Remove any personally identifiable or sensitive information on customers.
```{r}
toys_joined <- toys_joined %>% select(-c("first_name", "last_name", "customer_height_cm",
"customer_weight_kg"))
```


10
Write your new joined dataset (which does not contain personal/sensitive information) to a csv file.
```{r}
write_csv(toys_joined, "clean_data/toy_joined.csv")
```

11
Use a .gitignore file to make sure the raw data on customers which still contains personal/sensitive information is not pushed up to your PDA GitHub.



